render_eml("metadata/site.xml", outfile = "site.html", output_dir = "/metadata")
render_eml("metadata/site.xml", outfile = "site.html", output_dir = "metadata/")
source('~/Desktop/lobster-collectors/metadata/metadata.R', echo=TRUE)
render_eml("metadata/site.xml", outfile = "site.html", output_dir = "/metadata/")
install.packages(c("assertthat", "backports", "BH", "bookdown", "boot", "Cairo", "callr", "class", "cli", "clipr", "cluster", "coda", "codetools", "colorspace", "commonmark", "crosstalk", "curl", "deldir", "Deriv", "devtools", "digest", "doParallel", "dplyr", "evaluate", "expm", "fansi", "fields", "foreach", "foreign", "fs", "ggplot2", "gh", "git2r", "glue", "gtable", "gtools", "highr", "htmltools", "htmlwidgets", "httpuv", "httr", "igraph", "isoband", "iterators", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lazyeval", "loo", "manipulateWidget", "markdown", "MASS", "Matrix", "matrixStats", "mcmc", "mgcv", "mime", "mnormt", "mvtnorm", "nimble", "nlme", "nnet", "numDeriv", "officer", "openssl", "permute", "pillar", "pkgbuild", "pkgconfig", "plyr", "polynom", "prettyunits", "processx", "promises", "ps", "purrr", "quantreg", "R6", "raster", "rcmdcheck", "Rcpp", "RcppEigen", "remotes", "reshape2", "rgdal", "rgl", "rjags", "rmarkdown", "RODBC", "rpart", "rstan", "rstudioapi", "scales", "shiny", "sn", "sp", "spam", "SparseM", "spData", "spdep", "StanHeaders", "stringi", "stringr", "survival", "tibble", "tidyselect", "tinytex", "TMB", "usethis", "uuid", "vegan", "webshot", "whisker", "withr", "xfun", "xml2", "xslt", "xtable", "yaml", "zip"))
library(gulf.utils)
library(gulf.data)
files = dir.github(username = 'TobieSurette', repo = 'lobster-collectors')
files <- files[intersect(grep('minilog', files), grep('2019', files))]
x <- read.minilog(file = files[1])
x
header(x)
t(header(x))
t(header(x))[, 1]
t(header(x))
describe(x)
source('~/Desktop/gulf.data/R/minilog.R', echo=TRUE)
source('~/Desktop/gulf.data/R/read.minilog.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
attributes(x)
library(gulf.utils)
library(gulf.data)
files = dir.github(username = 'TobieSurette', repo = 'lobster-collectors')
files <- files[intersect(grep('minilog', files), grep('2019', files))]
x <- read.minilog(file = files[1])
head(x)
units(x)
x <- read.minilog(file = files[1:2])
x <- read.minilog(file = files)
dim(x)
head(x)
x <- read.minilog(file = files[1])
attributes(x)
x <- read.minilog(file = files[1])
i = 1
tmp <- read.minilog(file = files[i])
header(tmp)
header(tmp)$Source.Device
x <- NULL
for (i in 1:length(files)){
tmp <- read.minilog(file = files[i])
tmp$device <- as.character(header(tmp)$Source.Device)
x  <- rbind(x, tmp)
}
x <- NULL
for (i in 1:length(files)){
tmp <- read.minilog(file = files[i])
tmp$device <- as.character(header(tmp)$Source.Device)
x  <- rbind(x, tmp)
print(as.character(header(tmp)$Study.Description))
}
str <- as.character(header(tmp)$Study.Description)
strplit(str, sep = "2019")
str <- as.character(header(tmp)$Study.Description)
strsplit(str, sep = "2019")
strsplit(str, "2019")
strsplit(str, "2019")[[1]][1]
str <- as.character(header(tmp)$Study.Description)
strsplit(str, " 2019")[[1]][1]
x <- NULL
for (i in 1:length(files)){
tmp <- read.minilog(file = files[i])
tmp$device <- as.character(header(tmp)$Source.Device)
str <- as.character(header(tmp)$Study.Description)
str <- strsplit(str, " 2019")[[1]][1]
tmp$site <- str
x  <- rbind(x, tmp)
}
head(x)
tmp <- read.minilog(file = files[i])
device <- as.character(header(tmp)$Source.Device)
site <- as.character(header(tmp)$Study.Description)
site <- strsplit(str, " 2019")[[1]][1]
site <- str
tmp <- cbind(device = device, site = site, tmp)
head(tmp)
describe(x)
describe(tmp)
files = dir.github(username = 'TobieSurette', repo = 'lobster-collectors')
files <- files[intersect(grep('minilog', files), grep('2019', files))]
x <- NULL
for (i in 1:length(files)){
tmp <- read.minilog(file = files[i])
device <- as.character(header(tmp)$Source.Device)
site <- as.character(header(tmp)$Study.Description)
site <- strsplit(str, " 2019")[[1]][1]
site <- str
tmp <- cbind(device = device, site = site, tmp)
x  <- rbind(x, tmp)
}
key(x)
attributes(x)
class(x)
source('~/Desktop/lobster-collectors/export/minilog.R', echo=TRUE)
files
library(gulf.data)
locate("collector.csv")
getwd()
locate(pattern = "collector.csv")
read.csv("data/collector.csv", header = TRUE, stringsAsFactors = FALSE)
library(gulf.data)
locate(pattern = "collector.csv")
x <- read.csv("data/collector.csv", header = TRUE, stringsAsFactors = FALSE)
head(x)
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
table(x$year, x$site)
head(x)
x$size
table(x$year, x$site)
x$species
head(x)
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x$species == "Homarus americanus"
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
table(x$year, x$site)
x <- x[x$year == 2019, ]
head(x)
dim(x)
x$carapace.width
x$ssize
x$size
library(gulf.graphics)
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2019, ]
table(x$size)
gbarplot(table(x$size))
gbarplot(table(x$size), width = 0.1)
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- x[x$year == 2018, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2018, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2017, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2016, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2015, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
x <- read.csv("data/biological.csv", header = TRUE, stringsAsFactors = FALSE)
x <- x[x$species == "Homarus americanus", ]
x <- x[x$year == 2019, ]
gbarplot(table(x$size), width = 0.1, xlab = "Carapace length(mm)", ylab = "Frequency")
library(gulf.data)
library(gulf.utils)
library(gulf.data)
files <- dir(path = "data/raw/minilog", full.names = TRUE)
# Read the first file:
x <- read.minilog(file = files[1], project = "collectors")
# Plot the first file:
plot(time(x), x$temperature, pch = 21, bg = "grey", cex = 0.5,
xlab = "Date", ylab = "Temperature", main = header(x)$Study.Description)
library(gulf)
language <- "french"
jpeg <- FALSE
# Load data file HERE:
# read.csv(filename, )
# data file is assumed to have 'year', 'site' and 'n' fields:
data <- read.csv("/Users/crustacean/Desktop/lobster-collectors/data/Biological.csv", stringsAsFactors = FALSE)
names(data) <- tolower(names(data))
data$n <- data$nyoy
# Treat missing values as zero yoy observations:
data$n[is.na(data$n)] <- 0
# Site reformats:
data$site <- gsub("Fortune[12]", "Fortune", data$site) # Combine Fortune sites.
data$site[data$site %in% c("Skinner's pond", "Skinner's Pond ")] <- "Skinner's Pond"
# Keep track of sites in years with no observations:
zeroes <- aggregate(list(mean = data[,"n"]), by = data[c("site", "year")], mean)
zeroes <- zeroes[zeroes$mean == 0, ]
# Remove null sites from analysis:
data <- data[is.na(match(data[c("site", "year")], zeroes[c("site", "year")])), ]
data$site <- as.factor(data$site)
data$year <- factor(data$year, levels = sort(unique(data$year)))
# Fit model:
m <- glm(n ~ site * year, family = poisson, data = data)
# Calculate indices:
newdata <- aggregate(data["n"], by = data[c("site", "year")], mean)
newdata <- newdata[newdata$n > 0, 1:2]
res <- predict(m, newdata = newdata, se.fit = TRUE)
# Compile results:
results <- data.frame(mean = exp(res$fit),
lower.ci = exp(res$fit - 1.96 * res$se.fit),
upper.ci = exp(res$fit + 1.96 * res$se.fit))
results <- cbind(newdata, results / 0.557) # Standardize to one square meter.
# Add zeroes to results:
zeroes$lower.ci <- 0
zeroes$upper.ci <- 0
results <- rbind(results, zeroes)
sites <- unique(results$site)
cols <- rainbow(length(sites))
results$year <- as.numeric(as.character(results$year))
results <- sort(results, by = c("site", "year"))
# Quick plot:
windows()
plot(range(results$year), c(0, 1.2*max(results$mean)), type = "n")
for (i in 1:length(sites)){
r <- results[results$site == sites[i], ]
print(r)
lines(r$year, r$mean, col = cols[i], lwd = 2)
}
legend("topleft", legend = sites, col = cols, lwd = 2)
if (jpeg){
jpeg(filename = paste0("Lobster Yoy Abundance Collector - ", language, ".jpeg"), width = 600 * 8, height = 600 * 8, res = 75 * 8)
}else{
clg()
windows(width = 8.5, height = 8.5)
}
m <- kronecker(matrix(1:2, ncol = 1), matrix(1, ncol = 5, nrow = 5))
m <- rbind(0, cbind(0, m, 0), 0, 0)
layout(m)
par(mar = c(0,0,0,0))  #   c(bottom, left, top, right)
sites <- c("Alberton", "Covehead", "Skinner's Pond", "Egmont Bay", "Fortune", "Murray Harbour",  "Arisaig", "Neguac", "Nine Mile Creek")
results$site <- as.character(results$site)
lty <- c("solid", "dashed", "dotted")
cols <- c("black", "grey40", "grey70")
pch <- 21:23
# Define axis labels:
if (language == "english") xlab <- "Year" else xlab <- "Ann?e"
if (language == "english") ylab <- expression(paste("Number per m"^"2")) else ylab <- expression(paste("Nombre par m"^"2"))
xlim <- range(results$year)
for (i in 1:2){
jj <- (i-1)*3 + (1:3)
if (i == 3) jj <- jj[c(1, 3)]
ylim <- c(0, 1.1 * max(results$upper.ci[results$site %in% sites[jj]]))
plot(xlim, ylim, type = "n", xaxt = "n", yaxt = "n", xlab = "", ylab = "", yaxs = "i")
grid()
for (j in 1:length(jj)){
r <- results[results$site %in% sites[jj][j], ]
missing <- setdiff(min(r$year):max(r$year), r$year)
if (length(missing) > 0){
r <- rbind(r, data.frame(site = r$site[1], year = missing, mean = NA, lower.ci = NA, upper.ci = NA))
r <- r[order(r$year), ]
}
lines(r$year, r$mean, col = cols[j], lwd = 2, lty = lty[j])
for (k in 1:nrow(r)){
lines(rep(r$year[k], 2), c(r$lower.ci[k], r$upper.ci[k]), col = cols[j], lty = lty[j], lwd = 2)
lines(c(r$year[k] - 0.10, r$year[k] + 0.10), rep(r$lower.ci[k], 2), col = cols[j], lty = lty[j], lwd = 2)
lines(c(r$year[k] - 0.10, r$year[k] + 0.10), rep(r$upper.ci[k], 2), col = cols[j], lty = lty[j], lwd = 2)
}
}
other <- c("24", "24", "25N", "25S", "26APEI", "26APEI")
str <- sites[jj]
if (language == "french") str <- gsub("Egmont Bay", "Baie Egmont", str)
legend("topleft", legend = paste0(str, " (", other[jj], ")"), col = cols[1:length(jj)], lwd = 2, bg = "white", cex = 1.6, lty = lty[1:length(jj)],
pch = pch[1:length(jj)], pt.bg = cols[1:length(jj)])
if (i == 1) at <- seq(0, 35, by = 5)
if (i == 2) at <- seq(0, 5, by = 1)
if (i == 3) at <- seq(0, 2, by = 0.5)
axis(2, at = at, cex.axis = 1.2)
if (i == 1) mtext(ylab, 2, 3, at = 0, cex = 1.5)
box()
for (j in 1:length(jj)){
r <- results[results$site %in% sites[jj][j], ]
points(r$year, r$mean, pch = pch[j], bg = cols[j], cex = 1.75)
}
}
axis(1, at = seq(min(results$year), max(results$year), by = 2), cex.axis = 1.2)
axis(1, at = seq(min(results$year)+1, max(results$year), by = 2), cex.axis = 1.2)
mtext(xlab, 1, 3.5, cex = 1.5)
if (jpeg) dev.off()
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
names(x)
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x)
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str
str[str == "site_name"] <- "site"
str
names(x) <- str
str
str[str == "site_name"] <- "site"
names(x) <- str
str
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str[str == "site_name"] <- "site"
str[str == "c_enter_lat"] <- "latitude"
str[str == "c_enter_lon"] <- "longitude"
str[str == "comments"] <- "comment"
names(x) <- str
names(x)
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
names(x)
str <- names(x)
str
str[str == "site_name"] <- "site"
str[str == "c_enter_lat"] <- "latitude"
str[str == "c_enter_lon"] <- "longitude"
str[str == "comments"] <- "comment"
names(x) <- str
str
str
# Define variables to keep in the output:
vars <- c("year", "site", "collector", "condition", "comment")
# Load lobster larvae collector table:
x <- read.csv("https://raw.github.com/TobieSurette/lobster-collectors/master/data/raw/129_Collector_Table_08_18.csv", stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str[str == "site_name"] <- "site"
str[str == "r_year"] <- "year"
str[str == "coll_no"] <- "collector"
str[str == "ret_comments"] <- "comment"
str[str == "cond_ret"] <- "condition"
names(x) <- str
str
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str[str == "site_name"] <- "site"
str[str == "c_enter_lat"] <- "latitude"
str[str == "c_enter_lon"] <- "longitude"
str[str == "comments"] <- "comment"
names(x) <- str
str
# Define variables to keep in the output:
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str
str[str == "site_name"] <- "site"
str
str[str == "c_enter_lat"] <- "latitude"
str[str == "c_enter_lon"] <- "longitude"
str[str == "comments"] <- "comment"
names(x) <- str
str
# Correct coordinate fields:
x$longitude <- -abs(x$longitude)
x$latitude  <- abs(x$latitude)
x$date.deployed  <- as.character(as.Date(paste0(x$s_year, "-", x$s_month, "-", x$s_day)))
x$date.retrieved <- as.character(as.Date(paste0(x$r_year, "-", x$r_month, "-", x$r_day)))
library(gulf.data)
excel(x)
x$year <- as.numeric(substr(x$date.deployed, 1, 4))
x <- x[vars]
excel(x)
y <- aggregate(x[c("longitude", "latitude")], by = x["site"], mean, na.rm = TRUE)
y
y <- aggregate(x[c("longitude", "latitude","year")], by = x["site"], mean, na.rm = TRUE)
y
y <- aggregate(x[c("longitude", "latitude","year")], by = x["site"], mean, na.rm = TRUE)
y
y <- aggregate(x[c("longitude", "latitude","year")], by = x["site","year"], mean, na.rm = TRUE)
getwd
getwd()
write.table(x, file = "/data/site.csv", col.names = TRUE, row.names = FALSE, sep = ",")
write.table(x, file = "data/site.csv", col.names = TRUE, row.names = FALSE, sep = ",")
vars <- c("year", "site", "longitude", "latitude", "date.deployed", "date.retrieved", "comment")
# Load lobster collector site table:
x <- read.csv("data/raw/129_Site_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str[str == "site_name"] <- "site"
str[str == "c_enter_lat"] <- "latitude"
str[str == "c_enter_lon"] <- "longitude"
str[str == "comments"] <- "comment"
names(x) <- str
# Correct coordinate fields:
x$longitude <- -abs(x$longitude)
x$latitude  <- abs(x$latitude)
# Format date fields:
x$date.deployed  <- as.character(as.Date(paste0(x$s_year, "-", x$s_month, "-", x$s_day)))
x$date.retrieved <- as.character(as.Date(paste0(x$r_year, "-", x$r_month, "-", x$r_day)))
x$year <- as.numeric(substr(x$date.deployed, 1, 4))
# Remove irrelevant fields:
x <- x[vars]
y <- aggregate(x[c("longitude", "latitude")], by = x["site"], mean, na.rm = TRUE)
y$station <- NA
y$depth <- NA
output_dir
write.table(x, file = "data/site.csv", col.names = TRUE, row.names = FALSE, sep = ",")
# Define variables to keep in the output:
vars <- c("year", "site", "collector", "condition", "comment")
# Load lobster larvae collector table:
x <- read.csv("data/raw/129_Collector_Table.csv", header = TRUE, stringsAsFactors = FALSE)
names(x) <- tolower(names(x))
# Change field names:
str <- names(x)
str[str == "site_name"] <- "site"
str[str == "r_year"] <- "year"
str[str == "coll_no"] <- "collector"
str[str == "ret_comments"] <- "comment"
str[str == "cond_ret"] <- "condition"
names(x) <- str
str
x
library(gulf.data)
excel(x)
# Collector condition table:
conditions <- c("OK", "<1/2", ">1/2", "Damaged", "Lost")
x$condition <- conditions[x$condition]
excel(x)
# Remove irrelevant fields:
x <- x[vars]
write.table(x, file = "data/collector.csv", col.names = TRUE, row.names = FALSE, sep = ",")
y <- read.csv("data/raw/129_Crab_Fish_table.csv", stringsAsFactors = FALSE)
names(y) <- tolower(names(y))
y$year <- y$r_year
y$species <- paste(y$genus, y$species)
y$site <- y$site_name
y$collector <- y$coll_no
y$size <- y$length_mm
y$weight <- y$weight_g
y$sex <- toupper(y$sex)
y$sex[y$sex == "2"] <- "F"
y$comment <- y$comments
library(gulf.data)
excel(y)
excel(y)
# Define variables to keep in the output:
vars <- c("year", "site", "collector", "species", "sex", "size", "weight", "comment")
# Load data:
y <- read.csv("data/raw/129_Crab_Fish_table.csv", stringsAsFactors = FALSE)
names(y) <- tolower(names(y))
y$year <- y$r_year
y$species <- paste(y$genus, y$species)
y$site <- y$site_name
y$collector <- y$coll_no
y$size <- y$length_mm
y$weight <- y$weight_g
y$sex <- toupper(y$sex)
y$sex[y$sex == "2"] <- "F"
y$comment <- y$comments
# Remove irrelevant fields:
x <- x[vars]
#
# # Load 2019 data:
# x <- read.csv("https://raw.github.com/TobieSurette/lobster-collectors/master/data/raw/Collector%20Data%202019.csv", stringsAsFactors = FALSE)
# names(x) <- tolower(names(x))
#
# # Create year field:
# x$year <- 2019
#
# # Variable name corrections:
# str <- names(x)
# x$size <- x$size.cl..cw.or.tl
# x$weight <- NA
# x$collector <- x$collector.number
# x$comment  <- x$notes
#
# # Clean up study area field:
# x$study.area <- gsub("\n", "", x$study.area)
#
# # Clean up sex field:
# x$sex <- toupper(x$sex)
#
# # Remove empty observations:
# x <- x[!is.na(x$size) | x$sex != "", ]
# Clean up comments:
#x$comment <- gsub(",", ";", x$comment)
#
# # Combine data sets:
# x <- rbind(x[vars], y[vars])
# Output to file:
# Define variables to keep in the output:
vars <- c("year", "site", "collector", "species", "sex", "size", "weight", "comment")
# Load data:
y <- read.csv("data/raw/129_Crab_Fish_table.csv", stringsAsFactors = FALSE)
names(y) <- tolower(names(y))
y$year <- y$r_year
y$species <- paste(y$genus, y$species)
y$site <- y$site_name
y$collector <- y$coll_no
y$size <- y$length_mm
y$weight <- y$weight_g
y$sex <- toupper(y$sex)
y$sex[y$sex == "2"] <- "F"
y$comment <- y$comments
# Remove irrelevant fields:
y <- y[vars]
#
excel(y)
